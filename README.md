# ğŸ”¬ Deep-Viz: Unveiling the Black Box of Deep Learning

<div align="center">

![Deep Learning Visualization](https://img.shields.io/badge/Deep%20Learning-Visualization-blue?style=for-the-badge&logo=pytorch)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)

*"Seeing is believing, but understanding is enlightening"* ğŸ§ âœ¨

</div>

## ğŸŒŸ What is Deep-Viz?

Deep-Viz is an interactive web application that makes AI interpretability accessible to everyone! Ever wondered what a neural network "sees" when it looks at an image? This tool pulls back the curtain on deep learning models, revealing the hidden patterns and decision-making processes that drive AI predictions.

## ğŸ¯ Features

### ğŸ” **Model Interpretability Made Simple**
- **Class Activation Maps (CAM)** using SmoothGradCAM++ ğŸ¨
- **Integrated Gradients** for pixel-level feature attribution ğŸ“Š
- **Real-time visualization** of model predictions ğŸš€
- **Multi-model support** (ResNet18 & ResNet50) âš™ï¸

### ğŸ¨ **Interactive Experience**
- **Drag-and-drop** image upload ğŸ“¤
- **Layer-wise exploration** of neural network activations ğŸ”¬
- **Top-5 predictions** with confidence scores ğŸ“ˆ
- **Side-by-side comparison** of different visualization techniques ğŸ”„

## ğŸ§  How It Works

```mermaid
graph TD
    A[ğŸ“· Upload Image] --> B[ğŸ”„ Preprocessing]
    B --> C[ğŸ¤– ResNet Model]
    C --> D[ğŸ“Š Predictions]
    C --> E[ğŸ¨ SmoothGradCAM++]
    C --> F[ğŸ” Integrated Gradients]
    
    D --> G[ğŸ“ˆ Top-5 Results]
    E --> H[ğŸ—ºï¸ Class Activation Map]
    F --> I[âš¡ Attribution Heatmap]
    
    G --> J[ğŸ“± Interactive Dashboard]
    H --> J
    I --> J
    
    style A fill:#ff6b6b
    style C fill:#4ecdc4
    style J fill:#45b7d1
```

## ğŸš€ Quick Start

### Prerequisites
Make sure you have Python 3.7+ installed on your system.

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/nevrohelios/deep-viz.git
cd deep-viz
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Launch the application**
```bash
streamlit run main.py
```

4. **Open your browser** and navigate to `http://localhost:8501` ğŸŒ

## ğŸ“š Understanding the Visualizations

### ğŸ¨ Class Activation Maps (CAM)
CAMs highlight the regions in an image that are most important for the model's prediction. Think of it as the model's "attention map" - where is it looking when making decisions?

```
ğŸ–¼ï¸ Original Image â†’ ğŸ”¥ Heat Map â†’ ğŸ¯ Important Regions
```

### âš¡ Integrated Gradients
This technique provides pixel-level attributions, showing how much each pixel contributes to the final prediction. It's like having X-ray vision into the model's decision process!

```
ğŸ” Pixel Analysis â†’ ğŸ“Š Attribution Scores â†’ ğŸ¨ Visualization
```

## ğŸ”§ Technical Architecture

### ğŸ“¦ Core Components

| Component | Purpose | Technology |
|-----------|---------|------------|
| ğŸ¨ **Frontend** | Interactive UI | Streamlit |
| ğŸ¤– **Model Backend** | Deep Learning | PyTorch + TorchVision |
| ğŸ” **Interpretability** | CAM Generation | TorchCAM |
| âš¡ **Attribution** | Gradient Analysis | Captum |
| ğŸ–¼ï¸ **Image Processing** | Preprocessing | PIL + Transforms |

### ğŸ—ï¸ Model Architecture

```
Input Image (224Ã—224Ã—3)
     â†“
ResNet18/50 Backbone
     â†“
Feature Extraction
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAM Extraction â”‚ Gradient Flow   â”‚
â”‚  (TorchCAM)     â”‚ (Captum)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
Visualization Pipeline
     â†“
Interactive Dashboard
```

## ğŸ® Usage Examples

### ğŸ• Example 1: Animal Classification
Upload a photo of your pet and see which features the model uses to identify the animal!

### ğŸï¸ Example 2: Scene Understanding
Try landscape photos to understand how the model recognizes different environments.

### ğŸš— Example 3: Object Detection
Upload images with vehicles to see how the model focuses on distinctive features.

## ğŸ”¬ Advanced Features

### ğŸ›ï¸ **Layer Selection**
Explore different layers of the neural network to understand how features evolve from simple edges to complex patterns:

- **Early Layers**: Edge detection, basic shapes ğŸ“
- **Middle Layers**: Textures, patterns ğŸŒ€
- **Deep Layers**: Complex objects, semantic features ğŸ—ï¸

### ğŸ“Š **Model Comparison**
Switch between ResNet18 and ResNet50 to see how model depth affects interpretation:

| Model | Parameters | Speed | Accuracy |
|-------|------------|-------|----------|
| ResNet18 | 11.7M | âš¡ Fast | ğŸ¯ Good |
| ResNet50 | 25.6M | ğŸŒ Slower | ğŸ¯ Better |

## ğŸ”® What Makes This Special?

### ğŸ¨ **Visual Excellence**
- Clean, intuitive interface designed for both beginners and experts
- Real-time processing with smooth animations
- High-quality visualizations that reveal model insights

### ğŸ§ª **Educational Value**
- Perfect for students learning about AI interpretability
- Demonstrates cutting-edge explainable AI techniques
- Bridges the gap between theory and practice

### ğŸš€ **Production Ready**
- Robust error handling and user feedback
- Optimized for performance
- Extensible architecture for adding new models

## ğŸ› ï¸ Dependencies

```python
# Core ML Framework
torch              # PyTorch deep learning framework
torchvision        # Computer vision utilities
torchcam           # Class Activation Mapping

# Interpretability
captum             # Model interpretability library

# Web Framework
streamlit          # Interactive web applications

# Image Processing
pillow             # Python Imaging Library
numpy              # Numerical computing
matplotlib         # Plotting library
```

## ğŸ”„ Future Enhancements

- [ ] ğŸ¯ **More Models**: Add support for Vision Transformers, EfficientNet
- [ ] ğŸ¨ **Advanced Visualizations**: GradCAM, LIME, SHAP
- [ ] ğŸ“± **Mobile Support**: Responsive design for mobile devices
- [ ] ğŸ”— **API Integration**: REST API for programmatic access
- [ ] ğŸ¥ **Video Analysis**: Extend to video classification
- [ ] ğŸŒ **Multi-language**: Support for multiple languages

## ğŸ¤ Contributing

We welcome contributions! Whether it's:
- ğŸ› Bug fixes
- âœ¨ New features
- ğŸ“š Documentation improvements
- ğŸ¨ UI/UX enhancements

Please feel free to open issues and pull requests!

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **PyTorch Team** for the amazing deep learning framework ğŸ”¥
- **Streamlit** for making web apps incredibly simple ğŸš€
- **Captum** for state-of-the-art interpretability tools ğŸ”
- **TorchCAM** for excellent CAM implementations ğŸ¨

---

<div align="center">

**Made with â¤ï¸ and lots of â˜•**

*Star â­ this repo if you found it helpful!*

</div>
